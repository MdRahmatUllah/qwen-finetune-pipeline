# Environment variables for Qwen Fine-tuning Pipeline
# Copy this file to .env and customize as needed

# HuggingFace Hub Token (optional, for private models or faster downloads)
# Get your token from: https://huggingface.co/settings/tokens
# HF_TOKEN=your_huggingface_token_here

# CUDA/GPU Configuration
# CUDA_VISIBLE_DEVICES=0  # Specify which GPU(s) to use (e.g., "0,1" for multi-GPU)

# Training Configuration Overrides (optional)
# These override values in configs/train_qlora.yaml
# BATCH_SIZE=1
# GRADIENT_ACCUMULATION_STEPS=64
# LEARNING_RATE=2e-4
# NUM_EPOCHS=2

# Model Configuration
# BASE_MODEL=Qwen/Qwen2.5-7B
# OUTPUT_DIR=models/lora

# Logging and Monitoring (optional)
# WANDB_API_KEY=your_wandb_key_here  # For Weights & Biases logging
# WANDB_PROJECT=qwen-finetune
# WANDB_ENTITY=your_username

# Cache Directories (optional)
# HF_HOME=~/.cache/huggingface  # HuggingFace cache location
# TRANSFORMERS_CACHE=~/.cache/huggingface/transformers

# Performance Tuning
# OMP_NUM_THREADS=8  # OpenMP threads for CPU operations
# TOKENIZERS_PARALLELISM=false  # Disable tokenizer parallelism warnings

